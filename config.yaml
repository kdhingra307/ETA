model:
  working_dir: './data'
  batch_size: 16
  training_label: "melr_lstm_conv1d"
  num_nodes: 207

data:
  shuffle: 1000
  prefetch: 10
  path_pattern: "training_files"
  split_prefix: "melr_{}"

training:
  learning_rate: 0.00001
  decay: 1e+3
  log_dir: 'logs/{}'
  ckpt_dir: 'ckpt/{}'
  epochs: 50
  reset: False