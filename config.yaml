model:
  working_dir: "./data"
  batch_size: 16
  training_label: "small_eta/lstm/1"
  num_nodes: 2801
  steps_to_predict: 6
  ttr: 1

data:
  shuffle: 1000
  prefetch: 10
  path_pattern: "training_files"
  split_prefix: "custom_{}"
  mean:
    - 1.45362457
    - 0.53708629
  std:
    - 1.65967594
    - 0.26022761

training:
  learning_rate: 0.0001
  decay: 1e+3
  log_dir: "logs/{}"
  ckpt_dir: "ckpt/{}"
  epochs: 100
  reset: False
